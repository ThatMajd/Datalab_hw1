{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start By loading API keys & define Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pinecone_key.txt\", mode=\"r\") as f:\n",
    "    PINECONE_KEY = f.read().strip()\n",
    "\n",
    "with open(\"cohere_key.txt\", mode=\"r\") as f:\n",
    "    COHERE_KEY = f.read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 11:14:51.018617: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-30 11:14:51.018720: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-30 11:14:52.041302: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-30 11:14:54.660307: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-30 11:15:01.532445: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer # type: ignore\n",
    "from datasets import load_dataset # type: ignore\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dataset': {'dataset_name': 'Ateeqq/news-title-generator',\n",
      "             'rec_num': 2000,\n",
      "             'split': 'train',\n",
      "             'text_field': 'text'},\n",
      " 'Embedding': {'model': 'all-MiniLM-L6-v2'},\n",
      " 'LLM': {'model': 'command-r-plus'},\n",
      " 'PineconeSettings': {'cloud': 'aws', 'region': 'us-east-1'}}\n"
     ]
    }
   ],
   "source": [
    "# Code is fully modular, you can set the settings you need and run the code\n",
    "SETTINGS = {\n",
    "    \"Embedding\": {\n",
    "        \"model\": \"all-MiniLM-L6-v2\"\n",
    "    },\n",
    "    \"Dataset\": {\n",
    "        \"dataset_name\": \"Ateeqq/news-title-generator\",\n",
    "        \"split\": \"train\",\n",
    "        \"text_field\": \"text\",\n",
    "        \"rec_num\": 2_000,\n",
    "    },\n",
    "    \"LLM\": {\n",
    "        \"model\": \"command-r-plus\",\n",
    "    },\n",
    "    \"PineconeSettings\": {\n",
    "        \"cloud\": \"aws\",\n",
    "        \"region\": \"us-east-1\"\n",
    "    }\n",
    "}\n",
    "# SETTINGS = {\n",
    "#     \"Embedding\": {\n",
    "#         \"model\": \"all-MiniLM-L6-v2\"\n",
    "#     },\n",
    "#     \"Dataset\": {\n",
    "#         \"dataset_name\": \"neural-bridge/rag-dataset-12000\",\n",
    "#         \"split\": \"train\",\n",
    "#         \"text_field\": \"context\",\n",
    "#         \"rec_num\": 1_000,\n",
    "#     },\n",
    "#     \"LLM\": {\n",
    "#         \"model\": \"command-r-plus\",\n",
    "#     },\n",
    "#     \"PineconeSettings\": {\n",
    "#         \"cloud\": \"aws\",\n",
    "#         \"region\": \"us-east-1\"\n",
    "#     }\n",
    "# }\n",
    "pprint(SETTINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_embedd_dataset(\n",
    "        dataset_name: str,\n",
    "        split: str = 'train',\n",
    "        model: SentenceTransformer = SentenceTransformer('all-MiniLM-L6-v2'),\n",
    "        text_field: str = 'Excerpt',\n",
    "        rec_num: int = 400\n",
    "\n",
    ") -> tuple:\n",
    "        \"\"\"\n",
    "        Load dataset and embed it using tranformer model\n",
    "        Args:\n",
    "                dataset_name: The name of the dataset\n",
    "                split: (relevant to huggingface)\n",
    "                model: SentenceTransformer model to embedd\n",
    "                text_field: the column to embed\n",
    "                rec_num: number of rows to embed\n",
    "        Returns:\n",
    "                full dataset and embedding of specific number of records\n",
    "        \"\"\"\n",
    "        print(\"Loading and embedding the dataset\")\n",
    "\n",
    "        # Dataset is clean and short, so no need for additional preprocessing or chunking\n",
    "    \n",
    "        # Load the dataset\n",
    "        dataset = load_dataset(dataset_name, split=split)\n",
    "        # print(dataset[text_field][:rec_num])\n",
    "        # Embed the first `rec_num` rows of the dataset  \n",
    "        embeddings = model.encode(dataset[text_field][:rec_num])\n",
    "        \n",
    "        return dataset, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pinecone_index(\n",
    "        index_name: str,\n",
    "        dimension: int,\n",
    "        metric: str = 'cosine',\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a pinecone index if it does not exist\n",
    "    Args:\n",
    "        index_name: The name of the index\n",
    "        dimension: The dimension of the index\n",
    "        metric: The metric to use for the index\n",
    "    Returns:\n",
    "        Pinecone: A pinecone object which can later be used for upserting vectors and connecting to VectorDBs\n",
    "    \"\"\"\n",
    "    print(\"Creating a Pinecone index...\")\n",
    "    pc = Pinecone(api_key=PINECONE_KEY)\n",
    "    existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "    if index_name not in existing_indexes:\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=dimension,\n",
    "            # Remember! It is crucial that the metric you will use in your VectorDB will also be a metric your embedding\n",
    "            # model works well with!\n",
    "            metric=metric,\n",
    "            spec=ServerlessSpec(**SETTINGS[\"PineconeSettings\"])\n",
    "        )\n",
    "    print(\"Done!\")\n",
    "    return pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_vectors(\n",
    "        index: Pinecone,\n",
    "        embeddings: np.ndarray,\n",
    "        dataset: dict,\n",
    "        text_field: str = 'highlights',\n",
    "        batch_size: int = 128\n",
    "):\n",
    "    \"\"\"\n",
    "    Upsert vectors to a pinecone index\n",
    "    Args:\n",
    "        index: The pinecone index object\n",
    "        embeddings: The embeddings to upsert\n",
    "        dataset: The dataset containing the metadata\n",
    "        batch_size: The batch size to use for upserting\n",
    "    Returns:\n",
    "        An updated pinecone index\n",
    "    \"\"\"\n",
    "    print(\"Upserting the embeddings to the Pinecone index...\")\n",
    "    shape = embeddings.shape\n",
    "    \n",
    "    ids = [str(i) for i in range(shape[0])]\n",
    "    meta = [{text_field: text} for text in dataset[text_field]]\n",
    "    \n",
    "    # create list of (id, vector, metadata) tuples to be upserted\n",
    "    to_upsert = list(zip(ids, embeddings, meta))\n",
    "\n",
    "    for i in tqdm(range(0, shape[0], batch_size)):\n",
    "        i_end = min(i + batch_size, shape[0])\n",
    "        index.upsert(vectors=to_upsert[i:i_end])\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_prompt(\n",
    "        query: str,\n",
    "        model: SentenceTransformer = SentenceTransformer('all-MiniLM-L6-v2'),\n",
    "        index=None,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Augment the prompt with the top 3 results from the knowledge base\n",
    "    Args:\n",
    "        query: The query to augment\n",
    "        index: The vectorstore object\n",
    "    Returns:\n",
    "        str: The augmented prompt\n",
    "    \"\"\"\n",
    "\n",
    "    field = SETTINGS[\"Dataset\"][\"text_field\"]\n",
    "\n",
    "    results = [float(val) for val in list(model.encode(query))]\n",
    "    \n",
    "    # get top 3 results from knowledge base\n",
    "    query_results = index.query(\n",
    "        vector=results,\n",
    "        top_k=3,\n",
    "        include_values=True,\n",
    "        include_metadata=True\n",
    "    )['matches']\n",
    "    text_matches = [match['metadata'][field] for match in query_results]\n",
    "    \n",
    "    # get the text from the results\n",
    "    source_knowledge = \"\\n\\n\".join(text_matches)\n",
    "    \n",
    "    # feed into an augmented prompt\n",
    "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "    Contexts:\n",
    "    {source_knowledge}\n",
    "    If the answer is not included in the source knowledge - say that you don't know.\n",
    "    Query: {query}\"\"\"\n",
    "    return augmented_prompt, source_knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following class creates the RAG pipeline, given the SETTINGS dictionary the class will load and embed the dataset\n",
    "# create a pinecone index (if it doesn't already exist), upsert the data to Pinecone\n",
    "# Finally allows the end user to interact with the LLM in an easy and abstract manner\n",
    "class RAG:\n",
    "    def __init__(self, settings: dict) -> None:\n",
    "        self.fresh_index = False\n",
    "        self.model = self._load_embedding_model(settings[\"Embedding\"])\n",
    "        self.dataset, self.embeddings = self._load_and_embedd(settings[\"Dataset\"])\n",
    "        print(f'> Model and Data are loaded and data has been embedded with size {self.embeddings.shape}')\n",
    "        print(f'> Initializing Index')\n",
    "        self.index, self.pc = self._get_create_index(name=\"test\") # change name \n",
    "        if self.fresh_index:\n",
    "            print(f'> Index is empty upserting Data...')\n",
    "            upsert_vectors(self.index, self.embeddings, self.dataset, settings[\"Dataset\"][\"text_field\"])\n",
    "        pprint(self.index.describe_index_stats())\n",
    "        \n",
    "        self.LLM_model = settings[\"LLM\"][\"model\"]\n",
    "        self.co = self._init_LLM()\n",
    "        print(f'> LLM loaded')\n",
    "\n",
    "        pass\n",
    "\n",
    "    def prompt(self, query, add_context=False):\n",
    "        msg = query + \" be consciense and get straight the point, maximum of 3-4 lines, if you don't know say you don't know\"\n",
    "        source_knowledge = None\n",
    "        # if add_context is true add context\n",
    "        if add_context:\n",
    "            msg, source_knowledge = augment_prompt(msg, self.model, self.index)\n",
    "\n",
    "        response = self.co.chat(\n",
    "            model = self.LLM_model,\n",
    "            message=msg\n",
    "        )\n",
    "        return {\"text\": response.text,\n",
    "                \"query\": msg,\n",
    "                \"source_knowledge\": source_knowledge}\n",
    "\n",
    "    def _init_LLM(self):\n",
    "        return cohere.Client(COHERE_KEY)\n",
    "\n",
    "    def _load_embedding_model(self, model_settings):\n",
    "        return SentenceTransformer(model_settings[\"model\"])\n",
    "\n",
    "    def _load_and_embedd(self, dataset_settings):\n",
    "        recs = dataset_settings[\"rec_num\"]\n",
    "        print(f\"> Using {recs} records\")\n",
    "        return load_and_embedd_dataset(**dataset_settings, model=self.model)\n",
    "    \n",
    "    def _get_create_index(self, name):\n",
    "        pc = Pinecone(PINECONE_KEY)\n",
    "        if name not in [index_info[\"name\"] for index_info in pc.list_indexes()]:\n",
    "            create_pinecone_index(name, dimension=self.embeddings.shape[1])\n",
    "            self.fresh_index = True\n",
    "        else:\n",
    "            print(\"> Index exists, fetching it\")\n",
    "        self.index_name = name\n",
    "        return pc.Index(self.index_name), pc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Using 2000 records\n",
      "Loading and embedding the dataset\n",
      "> Model and Data are loaded and data has been embedded with size (2000, 384)\n",
      "> Initializing Index\n",
      "> Index exists, fetching it\n",
      "{'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 2000}},\n",
      " 'total_vector_count': 2000}\n",
      "> LLM loaded\n"
     ]
    }
   ],
   "source": [
    "# print(SETTINGS[\"Embedding\"])\n",
    "rag = RAG(settings=SETTINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def check_effictiveness(query):\n",
    "    \"\"\"\n",
    "    Test the performance of the RAG model by running it once without context from the database and another time with the context\n",
    "    The function prints an HTML table that summarizes the test\n",
    "    Args:\n",
    "        query: the query you want to test on\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    results.append(rag.prompt(query, add_context=False))\n",
    "    results.append(rag.prompt(query, add_context=True))\n",
    "    df = pd.DataFrame(results, columns=['text','query', 'source_knowledge'])\n",
    "    df.index = ['no', 'yes']\n",
    "    df.index.name = 'context?'\n",
    "    display(HTML(df.to_html()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>query</th>\n",
       "      <th>source_knowledge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context?</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>The last drilling performed by the Curiosity Rover was at a location named \"Cardiff\" on September 11, 2022. This site is located within the \"Clay-Bearing Unit,\" a region on Mount Sharp that is part of the Gale Crater on Mars.</td>\n",
       "      <td>Where did the Curiosity Rover drill its last drill? be consciense and get straight the point, maximum of 3-4 lines, if you don't know say you don't know</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>Rock Hall, Vera Rubin Ridge, Mars.</td>\n",
       "      <td>Using the contexts below, answer the query.\\n    Contexts:\\n    NASA's Curiosity rover has shared its last selfie clicked on Mars' Vera Rubin Ridge, which was its home for over a year. A series of 57 pictures were stitched together to create the selfie. Curiosity had drilled its 19th sample at 'Rock Hall' on the ridge on December 15, 2018, which is also visible in the photo, NASA added.\\n\\nIndian Navy divers on Saturday detected the body of another miner at a depth of 280 feet inside the flooded rat-hole in Meghalaya's East Jaintia Hills district, where 15 miners were trapped on December 13. \"During their search, the Navy team also stumbled on tell-tale signs like spades, a wooden cart and then located the dead miner,\" an official said.\\n\\nNASA's Opportunity rover has completed 15 years on Mars after it landed on January 24, 2004, and sent its first signal to Earth after a few hours. The solar-powered rover was designed to travel about 1 km and operate for 90 Martian days (sols). However, it has travelled over 45 km and logged its 5,000th sol as of February 2018.\\n    If the answer is not included in the source knowledge - say that you don't know.\\n    Query: Where did the Curiosity Rover drill its last drill? be consciense and get straight the point, maximum of 3-4 lines, if you don't know say you don't know</td>\n",
       "      <td>NASA's Curiosity rover has shared its last selfie clicked on Mars' Vera Rubin Ridge, which was its home for over a year. A series of 57 pictures were stitched together to create the selfie. Curiosity had drilled its 19th sample at 'Rock Hall' on the ridge on December 15, 2018, which is also visible in the photo, NASA added.\\n\\nIndian Navy divers on Saturday detected the body of another miner at a depth of 280 feet inside the flooded rat-hole in Meghalaya's East Jaintia Hills district, where 15 miners were trapped on December 13. \"During their search, the Navy team also stumbled on tell-tale signs like spades, a wooden cart and then located the dead miner,\" an official said.\\n\\nNASA's Opportunity rover has completed 15 years on Mars after it landed on January 24, 2004, and sent its first signal to Earth after a few hours. The solar-powered rover was designed to travel about 1 km and operate for 90 Martian days (sols). However, it has travelled over 45 km and logged its 5,000th sol as of February 2018.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NASA's Curiosity rover has shared its last selfie clicked on Mars' Vera Rubin Ridge, which was its home for over a year. A series of 57 pictures were stitched together to create the selfie. Curiosity had drilled its 19th sample at 'Rock Hall' on the ridge on December 15, 2018, which is also visible in the photo, NASA added.\n",
    "res = check_effictiveness(query=\"Where did the Curiosity Rover drill its last drill?\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>query</th>\n",
       "      <th>source_knowledge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facebook discontinued Moments on June 25.</td>\n",
       "      <td>On what date will facebook discontinue Moments no need to mention year?</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>February 25</td>\n",
       "      <td>Using the contexts below, answer the query.\\n    Contexts:\\n    Facebook will discontinue its standalone private photo and video-sharing app 'Moments', launched in 2015, on February 25 later this year. Users can retrieve the content stored on the app by either storing it on Facebook or downloading it to their device via a Facebook link. Facebook attributed the discontinuation to lesser people using the app but didn't share user numbers.\\n\\nFacebook is reportedly testing solar-powered internet drones, to beam internet connectivity from the Earth's stratosphere, in Australia with aeronautics company Airbus. It was in talks with Airbus to conduct test flights, scheduled for November and December 2018, with Airbus' Zephyr drone, the report added. In June 2018, Facebook had closed its solar-powered aircraft-building facility in the UK.\\n\\nFacebook is testing 'LOL' feature, a dedicated feed consisting of meme videos and other viral content. The feature, with content categorised by topics like 'For You', 'Animals', and 'Fails' is currently in private beta with around 100 high school students. Facebook said it is still finalising if the feature will become part of the main app or a standalone app.\\n    If the answer is not included in the source knowledge - say that you don't know.\\n    Query: On what date will facebook discontinue Moments no need to mention year?</td>\n",
       "      <td>Facebook will discontinue its standalone private photo and video-sharing app 'Moments', launched in 2015, on February 25 later this year. Users can retrieve the content stored on the app by either storing it on Facebook or downloading it to their device via a Facebook link. Facebook attributed the discontinuation to lesser people using the app but didn't share user numbers.\\n\\nFacebook is reportedly testing solar-powered internet drones, to beam internet connectivity from the Earth's stratosphere, in Australia with aeronautics company Airbus. It was in talks with Airbus to conduct test flights, scheduled for November and December 2018, with Airbus' Zephyr drone, the report added. In June 2018, Facebook had closed its solar-powered aircraft-building facility in the UK.\\n\\nFacebook is testing 'LOL' feature, a dedicated feed consisting of meme videos and other viral content. The feature, with content categorised by topics like 'For You', 'Animals', and 'Fails' is currently in private beta with around 100 high school students. Facebook said it is still finalising if the feature will become part of the main app or a standalone app.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_effictiveness(query=\"On what date will facebook discontinue Moments no need to mention year?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>query</th>\n",
       "      <th>source_knowledge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context?</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>The East Coast Rail Link (ECRL) project in Malaysia was planned to cost an estimated RM55 billion (US$13.1 billion) as of its suspension in 2018.</td>\n",
       "      <td>How much was East Coast Rail Link project planned to cost? be consciense and get straight the point, maximum of 3-4 lines, if you don't know say you don't know</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>The East Coast Rail Link project was planned to cost $20 billion.</td>\n",
       "      <td>Using the contexts below, answer the query.\\n    Contexts:\\n    Replying to an Australian lawmaker's query on Twitter, Musk quoted nearly $1 billion as the cost to build a 50-km-long commuter tunnel through Australia's Blue Mountain. \"[S]o probably around $750M plus maybe $50M/station,\" Musk added without specifying if he was referring to US dollars. Last year, Musk unveiled the first underground transportation tunnel in Los Angeles by The Boring Company.\\n\\nMalaysia's Economic Affairs Minister on Saturday said the country will cancel its $20-billion East Coast Rail Link (ECRL) project with contractor China Communications Construction. \"The... cost to develop the ECRL is too big and we don't have [the] financial capacity,\" he added. Malaysia had in August 2018 cancelled a natural gas pipeline project which was also backed by China.\\n\\nIndia's bullet train service will say \"sorry\" to every passenger even if the train is delayed by only a minute, the National High Speed Rail Corporation (NHSRCL) has decided. The Ahmedabad-Mumbai bullet train will see 70 trips per day, running at 320 kms per hour. The fares are expected to be around 1.5 times the fare of AC First Class.\\n    If the answer is not included in the source knowledge - say that you don't know.\\n    Query: How much was East Coast Rail Link project planned to cost? be consciense and get straight the point, maximum of 3-4 lines, if you don't know say you don't know</td>\n",
       "      <td>Replying to an Australian lawmaker's query on Twitter, Musk quoted nearly $1 billion as the cost to build a 50-km-long commuter tunnel through Australia's Blue Mountain. \"[S]o probably around $750M plus maybe $50M/station,\" Musk added without specifying if he was referring to US dollars. Last year, Musk unveiled the first underground transportation tunnel in Los Angeles by The Boring Company.\\n\\nMalaysia's Economic Affairs Minister on Saturday said the country will cancel its $20-billion East Coast Rail Link (ECRL) project with contractor China Communications Construction. \"The... cost to develop the ECRL is too big and we don't have [the] financial capacity,\" he added. Malaysia had in August 2018 cancelled a natural gas pipeline project which was also backed by China.\\n\\nIndia's bullet train service will say \"sorry\" to every passenger even if the train is delayed by only a minute, the National High Speed Rail Corporation (NHSRCL) has decided. The Ahmedabad-Mumbai bullet train will see 70 trips per day, running at 320 kms per hour. The fares are expected to be around 1.5 times the fare of AC First Class.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_effictiveness(\"How much was East Coast Rail Link project planned to cost?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>query</th>\n",
       "      <th>source_knowledge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context?</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>In 2018, Huawei was accused of copying a video created by a Dutch filmmaker, Maarten Paus, for one of their ads. The original video, titled \"The Story of a Boy Who Wants to Be Pictured,\" was allegedly imitated in Huawei's \"Be My Eyes\" ad campaign.</td>\n",
       "      <td>Which video was Huwaei accused to copying for an ad? be consciense and get straight the point, maximum of 3-4 lines, if you don't know say you don't know</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>Huawei was accused of copying Nigel Stanford's video \"Cymatics: Science Vs. Music\" for their ad promoting the 'MediaPad M3 Lite' tablet.</td>\n",
       "      <td>Using the contexts below, answer the query.\\n    Contexts:\\n    Chinese telecoms giant Huawei has been accused of copying a music video in an ad to promote its tablet 'MediaPad M3 Lite' by New Zealand composer Nigel Stanford. Huawei's ad video, allegedly similar to Stanford's video 'Cymatics: Science Vs. Music' released in 2014, was flagged by Stanford himself. \"We're looking into this matter and will share further updates,\" Huawei said.\\n\\nAs part of the viral #10YearChallenge, Anil Kapoor shared a collage of his videos from various years [1989, 1999, 2009 and 2019] and wrote, \"Forget the #10YearChallenge, take the #AKChallenge!\" The video includes songs from Anil's films 'Ram Lakhan', 'Taal', a scene from 'Slumdog Millionaire' and the latest song from his upcoming film 'Ek Ladki Ko Dekha Toh Aisa Laga'.\\n\\nUS President Donald Trump defended high school students who appeared to confront a Native American man in a viral video. The \"students were treated unfairly with early judgements proving out to be false - smeared by media\", Trump tweeted. Other videos showed a group of black protestors hurling slurs at the students, before their encounter with the Native American man.\\n    If the answer is not included in the source knowledge - say that you don't know.\\n    Query: Which video was Huwaei accused to copying for an ad? be consciense and get straight the point, maximum of 3-4 lines, if you don't know say you don't know</td>\n",
       "      <td>Chinese telecoms giant Huawei has been accused of copying a music video in an ad to promote its tablet 'MediaPad M3 Lite' by New Zealand composer Nigel Stanford. Huawei's ad video, allegedly similar to Stanford's video 'Cymatics: Science Vs. Music' released in 2014, was flagged by Stanford himself. \"We're looking into this matter and will share further updates,\" Huawei said.\\n\\nAs part of the viral #10YearChallenge, Anil Kapoor shared a collage of his videos from various years [1989, 1999, 2009 and 2019] and wrote, \"Forget the #10YearChallenge, take the #AKChallenge!\" The video includes songs from Anil's films 'Ram Lakhan', 'Taal', a scene from 'Slumdog Millionaire' and the latest song from his upcoming film 'Ek Ladki Ko Dekha Toh Aisa Laga'.\\n\\nUS President Donald Trump defended high school students who appeared to confront a Native American man in a viral video. The \"students were treated unfairly with early judgements proving out to be false - smeared by media\", Trump tweeted. Other videos showed a group of black protestors hurling slurs at the students, before their encounter with the Native American man.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_effictiveness(\"Which video was Huwaei accused to copying for an ad?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>query</th>\n",
       "      <th>source_knowledge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context?</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>Zhong Cheng Luo. He was a 26-year-old Chinese national and a postgraduate student at La Trobe University in Melbourne, Australia. He was fatally stabbed on campus in what police described as a \"horrendous, horrific attack.\"</td>\n",
       "      <td>What was the name of the student that was killed in Australia at La Trobe University? and who were they? be consciense and get straight the point, maximum of 3-4 lines, if you don't know say you don't know</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>Aiia Maasarwe was the name of the student who was killed in Australia while on a study abroad program at La Trobe University. She was an Israeli national.</td>\n",
       "      <td>Using the contexts below, answer the query.\\n    Contexts:\\n    An Israeli student was killed by an unknown assailant in Australia while she was on video call with her sister. Aiia Maasarwe had been in Australia for about six months on a study abroad program at La Trobe University. A detective said police believed it was a random attack, however, they hadn't ruled out possibility Maasarwe had been sexually assaulted.\\n\\nA 21-year-old student who was pursuing LLB from Delhi University was found hanging in the room of her paying guest accommodation in Noida on Sunday night. She allegedly committed suicide after a man whom she had befriended online didn't pick her calls following an argument, the police said. Her parents haven't filed a complaint, the police added.\\n\\nArchaeologists have found the remains of British explorer Captain Matthew Flinders, who is credited with naming Australia, near a railway station in London. Captain Flinders led the first circumnavigation of Australia. The discovery of his burial site was made as archaeologists were preparing the site where a railway station will be built.\\n    If the answer is not included in the source knowledge - say that you don't know.\\n    Query: What was the name of the student that was killed in Australia at La Trobe University? and who were they? be consciense and get straight the point, maximum of 3-4 lines, if you don't know say you don't know</td>\n",
       "      <td>An Israeli student was killed by an unknown assailant in Australia while she was on video call with her sister. Aiia Maasarwe had been in Australia for about six months on a study abroad program at La Trobe University. A detective said police believed it was a random attack, however, they hadn't ruled out possibility Maasarwe had been sexually assaulted.\\n\\nA 21-year-old student who was pursuing LLB from Delhi University was found hanging in the room of her paying guest accommodation in Noida on Sunday night. She allegedly committed suicide after a man whom she had befriended online didn't pick her calls following an argument, the police said. Her parents haven't filed a complaint, the police added.\\n\\nArchaeologists have found the remains of British explorer Captain Matthew Flinders, who is credited with naming Australia, near a railway station in London. Captain Flinders led the first circumnavigation of Australia. The discovery of his burial site was made as archaeologists were preparing the site where a railway station will be built.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_effictiveness(\"What was the name of the student that was killed in Australia at La Trobe University? and who were they?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:azureml_py38_PT_and_TF]",
   "language": "python",
   "name": "conda-env-azureml_py38_PT_and_TF-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
